
## 클래스와 메서드 정리

### 클래스(Class)

- **정의**: 객체(인스턴스)를 만들기 위한 설계도 또는 틀입니다.
- **역할**: 관련된 데이터(속성)와 동작(메서드)을 하나로 묶어 관리합니다.


### 메서드(Method)

- **정의**: 클래스 내부에 정의된 함수로, 인스턴스가 사용할 수 있습니다.
- **종류**
    - **생성자 메서드**: `__init__(self)`
        - 인스턴스가 생성될 때 자동으로 호출되어 초기 설정을 담당합니다.
        - `super(클래스명, self).__init__()`을 통해 부모 클래스의 초기화도 함께 실행할 수 있습니다.
    - **순전파(Forward) 메서드**:
        - 입력 데이터를 받아 모델의 출력을 계산하는 함수입니다.
        - 예시: `def forward(self, x): return self.linear(x)`


### 클래스와 메서드 예시 (PyTorch 선형회귀 모델)

```python
import torch.nn as nn

class LinearRegressionModel(nn.Module):
    def __init__(self): #생성자 메서드
        super(LinearRegressionModel, self).__init__()  # 부모 클래스 초기화
        self.linear = nn.Linear(1, 1)  # 속성: 선형 계층 정의

    def forward(self, x):
        y = self.linear(x)  # 메서드: 순전파 연산 정의
        return y

# 인스턴스 생성 예시
model = LinearRegressionModel()
```

- **self.linear**: 클래스 속성으로, 선형 계층(가중치와 바이어스 포함)을 정의합니다.
- **model = LinearRegressionModel()**: 인스턴스(객체) 생성 코드입니다.


## 선형 회귀 모델의 학습 방법과 학습 과정

### 선형 회귀 모델이란?

- **목적**: 입력 변수(특징, x)와 출력 변수(목표, y) 사이의 **선형 관계**를 찾아, 새로운 입력에 대해 연속적인 값을 예측하는 모델입니다.
- **수식**:


y = wx + b

    - w : 기울기(가중치)
    - b : y절편(바이어스)


### 학습 과정 요약

1. **트레이닝 데이터 준비**
    - 특징 변수(x)와 목표 변수(t)를 준비합니다.
2. **모델 정의**
    - 위의 클래스 예시처럼 선형 모델을 정의합니다.
3. **순전파(Forward)**
    - 입력 x를 모델에 넣어 예측값 y를 계산합니다.
4. **오차 계산**
    - 오차는 실제값(t)과 예측값(y)의 차이 $(t - y)$로 정의합니다.
    - 오차가 작을수록 모델의 예측이 실제에 가깝다는 뜻입니다.
5. **손실 함수(Loss Function)**
    - **목적**: 모델의 예측값과 실제값 사이의 차이를 수치로 평가합니다.
    - **주요 방식**:
        - **절대값 합**: $\sum |t - y|$
        - **제곱합(평균제곱오차, MSE)**: $\sum (t - y)^2$
            - 오차가 클수록 더 큰 패널티를 주어 학습이 더 잘 이루어지게 함
6. **최적화(Optimization)**
    - 손실 함수가 가장 작아지도록 가중치(w)와 바이어스(b)를 반복적으로 조정합니다.
    - 대표적으로 경사 하강법(Gradient Descent) 등의 알고리즘을 사용합니다.
7. **학습 완료 후 예측**
    - 학습이 끝나면, 모델은 새로운 x값에 대해 y값을 예측할 수 있습니다.

### 선형 회귀 학습 과정의 핵심 요약

- **트레이닝 데이터**로부터 **특징 변수와 목표 변수의 선형 관계**를 분석
- **상관관계 분석**을 통해 두 변수의 관계가 선형적인지 확인
- **모델 학습**은 \$ y = wx + b \$ 형태의 직선에서 w(기울기)와 b(절편)를 찾는 과정
- **손실 함수**(특히 평균제곱오차, MSE)를 최소화하는 방향으로 모델 파라미터를 업데이트
- 학습이 잘 되면, **새로운 데이터에 대해 연속적인 값**을 정확히 예측할 수 있음


### 참고: 신경망 관점에서의 선형 회귀

- 입력층의 특징 변수가 출력층의 예측 변수로 **직접 연결되는 가장 단순한 구조**입니다.
- 딥러닝 모델의 기본 블록으로도 자주 활용됩니다.

**정리:**
클래스와 메서드는 객체지향 프로그래밍의 기본 구조이며,
선형 회귀 모델은 입력과 출력 사이의 선형 관계를 학습해 새로운 값을 예측하는 가장 기본적인 머신러닝 모델입니다.
학습 과정은 오차와 손실함수를 최소화하는 방향으로 모델 파라미터를 반복적으로 조정하는 과정입니다.
