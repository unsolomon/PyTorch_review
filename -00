# 자원을 아끼기 위한 전략 세우기

1. 부동 소수점방식(01) 
고정 소수점
# 소수점 둘째 자리까지 항상 표현
fixed_point = 123.45
부동 소수점
# 가수부와 지수부로 나누어 표현
mantissa = 1.2345
exponent = 4
floating_point = mantissa * (10 ** exponent)  # 1.2345 * 10000 = 12345

소수점 위치를 자유롭게 바꿔서 훨씬 넓은 범위의 수를 같은 메모리로 저장하여 부동 소수점의 자원 절약 포인트

예시 1: 메모리 사용량 비교
import numpy as np

arr_fp32 = np.zeros(1000000, dtype=np.float32)  # 32비트 부동소수점
arr_fp16 = np.zeros(1000000, dtype=np.float16)  # 16비트 부동소수점

print(arr_fp32.nbytes)  # 4,000,000 bytes (약 4MB)
print(arr_fp16.nbytes)  # 2,000,000 bytes (약 2MB)

예시 2: 연산 속도 및 정확도 비교 (AI 모델)
# PyTorch 예시
import torch

a = torch.randn(10000, 10000, dtype=torch.float32)
b = torch.randn(10000, 10000, dtype=torch.float32)

# float32 연산
%timeit torch.matmul(a, b)

# float16 연산 (GPU에서 더 빠름)
a16 = a.half()
b16 = b.half()
%timeit torch.matmul(a16, b16)


# in-place 연산 활용 _언더바  
기존 텐서의 메모리 주소에 결과를 직접 저장하여, 새로운 텐서나 추가 메모리 공간을 만들지 않음
기존 a에 a와b의 결과값을 덮어 씌움

예 : torch.add(a,b) -> a.add_(b)




예시 4: 슬라이싱 & 메모리 연속성

| 함수명 | 주요 동작/목적 | 메모리 복사 발생 가능성 | 연속성 필요 | 특징 및 주의점 |
| :-- | :-- | :-- | :-- | :-- |
| view() | 임의 shape로 변환 | 없음 | 필요 | 연속적일 때만, 복사 없음 |
| reshape() | 임의 shape로 변환 | 있음 | 불필요 | 연속적이면 뷰, 아니면 복사 |
| flatten() | 1차원 평탄화 | 있음 | 불필요 | reshape(-1)과 유사, 항상 1차원 |
| transpose() | 두 차원 위치 맞바꿈 | 없음 | 불필요 | stride만 변경, 뷰 반환, 연속성 깨질 수 있음 |
| squeeze() | 크기 1인 차원 제거 | 없음 | 불필요 | 뷰 반환, 차원 1개 낮아짐 |
| unsqueeze() | 크기 1인 차원 추가 | 없음 | 불필요 | 뷰 반환, 차원 1개 높아짐 |
| stack() | 여러 텐서 새 축으로 쌓기 | 있음 | 불필요 | 입력 텐서 shape 동일 필요, 새로운 텐서 생성 |

메모리 복사 발생 가능성
없음:
기존 텐서의 메모리(주소)를 그대로 공유(뷰 반환), 데이터 복사 없음.

있음:
필요시(비연속적 등) 데이터를 새로운 메모리로 복사해 새 텐서 생성.



