
### L1, L2, L∞(무한대) 노름의 계산 방법과 활용

| **노름 종류**            | **계산 공식**                        | **계산 방법**                        | **주요 활용**                                                                 | **특징/차이점**                        |
|:-----------------------:|:-------------------------------------|:-------------------------------------|:-----------------------------------------------------------------------------|:----------------------------------------|
| **L1 노름**<br>(맨해튼 노름)   | ‖x‖₁ = ∑<sub>i=1</sub><sup>n</sup> \|xᵢ\|      | 각 원소의 절댓값을 모두 더함             | - L1 정규화<br>- Lasso 회귀<br>- 희소 모델링(Feature selection)<br>- 이상치에 강건한 손실 함수 | - 희소성을 유도<br>- 이상치에 강함      |
| **L2 노름**<br>(유클리드 노름) | ‖x‖₂ = √(∑<sub>i=1</sub><sup>n</sup> xᵢ²)      | 각 원소 제곱의 합에 루트                 | - L2 정규화<br>- Ridge 회귀<br>- 거리 기반 알고리즘(KNN, KMeans)<br>- 벡터의 일반적인 크기 측정 | - 직선 거리<br>- 모든 차원에 균등한 패널티<br>- 이상치에 민감 |
| **L∞ 노름**<br>(최대 노름)    | ‖x‖∞ = max<sub>i</sub> \|xᵢ\|                  | 원소 중 절댓값이 가장 큰 값을 취함        | - 로버스트 최적화<br>- 신경망에서 gradient clipping<br>- 최대 오류 제어                 | - 최대값에 민감<br>- 특정 차원 제약에 유용 |

#### 계산 예시 (벡터 a = [4, 3])

- **L1**: |4| + |3| = 7
- **L2**: √(4² + 3²) = √(16 + 9) = 5
- **L∞**: max(|4|, |3|) = 4

---

### 맨해튼, 유클리드, 코사인 유사도의 차이점 및 활용

| **유사도 종류**   | **계산 공식**                                         | **해석/특징**                                 | **주요 활용**                                 | **언제 사용?**                                 |
|:----------------:|:-----------------------------------------------------|:----------------------------------------------|:----------------------------------------------|:-----------------------------------------------|
| **맨해튼 유사도** | 1 / (1 + ∑<sub>i=1</sub><sup>n</sup> \|xᵢ − yᵢ\| )      | 거리의 총합(계단식), 1에 가까울수록 유사         | - 희소 데이터<br>- 빠른 근사 비교              | - 이상치에 강한 비교가 필요할 때               |
| **유클리드 유사도** | 1 / (1 + √(∑<sub>i=1</sub><sup>n</sup> (xᵢ − yᵢ)²))   | 직선 거리(최단 경로), 1에 가까울수록 유사        | - KNN, KMeans 등<br>- 이미지, 임베딩 간 거리 비교 | - 실제 거리 기반 판단이 필요할 때              |
| **코사인 유사도** | (x · y) / (‖x‖₂ × ‖y‖₂)                              | 두 벡터의 각도(방향) 비교, -1~1, 1에 가까울수록 유사 | - 문서/텍스트 유사도<br>- 임베딩 기반 검색<br>- 희소 벡터 | - 크기는 무시하고 방향만 비교할 때<br>- 벡터의 패턴이 중요한 경우 |



### 요약: 언제 어떤 노름/유사도를 써야 하나?

* **L1 노름**: 희소성 유도, 이상치에 강건한 모델이 필요한 경우
  → Lasso 회귀, 희소 feature 선택, 정규화, 로버스트 학습
* **L2 노름**: 일반적인 거리 계산, 모든 특성에 균형 있게 패널티 부여
  → Ridge 회귀, 거리 기반 알고리즘(KNN, SVM), 벡터 정규화
* **L∞ 노름**: 최대 요소 제어, 특정 값이 지나치게 크지 않도록 제한
  → Gradient clipping, 제한 최적화 문제, 안전 제약 조건
* **맨해튼/유클리드 유사도**: 거리 기반 비교. 값이 작을수록 유사
  → 데이터의 분포와 이상치 민감도를 고려해 선택
* **코사인 유사도**: 방향성 기반. 값이 1에 가까울수록 유사
  → 문서/텍스트 유사도, 임베딩 기반 검색, 크기 무시하고 방향 비교할 때



# PyTorch 행렬 곱셈 코드와 차이점 정리

### 1. 행렬 곱셈 코드 예시

```python
import torch

D = torch.tensor([[1, 1, 3],
                  [4, 5, 6],
                  [7, 8, 9]])

E = torch.tensor([[1, 0],
                  [1, -1],
                  [2, 1]])

# 방법 1: matmul
F1 = D.matmul(E)
print('D.matmul(E) =', F1)

# 방법 2: mm
F2 = D.mm(E)
print('D.mm(E) =', F2)

# 방법 3: @ 연산자
F3 = D @ E
print('D @ E =', F3)
```


### 2. 각 행렬 곱셈 함수/연산자의 차이점

| 구분 | 함수/연산자 | 지원 차원 | 특징 및 사용 시기 | 메모리/성능 |
| :-- | :-- | :-- | :-- | :-- |
| 함수 | `matmul()` | 1D, 2D, ND | **가장 범용적**. 벡터, 행렬, 배치 행렬 곱 모두 지원. | 새 메모리 생성 (out 지정 가능) |
| 함수 | `mm()` | 2D × 2D (행렬만) | **2차원 행렬 곱 전용**. 빠르고 단순. | 새 메모리 생성 (out 지정 가능) |
| 연산자 | `@` | 1D, 2D, ND | 파이썬 3.5+의 행렬 곱 연산자. 내부적으로 matmul 호출. | 새 메모리 생성 |

#### 상세 설명

- **matmul()**
    - 1D(벡터), 2D(행렬), N차원(배치 행렬) 곱까지 지원하는 가장 범용적인 함수입니다.
    - 예: (B, N, M) @ (B, M, K) → (B, N, K)
    - 내부적으로 입력 차원에 따라 dot, mm, bmm 등 적절한 연산이 자동 선택됨.
    - 실무에서 다양한 차원의 곱셈을 다룰 때 가장 많이 사용.
- **mm()**
    - 오직 2차원 행렬(2D) 곱만 지원합니다.
    - 벡터(1D)나 배치(3D 이상) 행렬에는 사용할 수 없습니다.
    - 2D 행렬 곱이 명확할 때 가장 빠르고 직관적.
- **@ 연산자**
    - 파이썬 표준 행렬 곱 연산자.
    - 내부적으로 torch.matmul을 호출.
    - 코드 가독성이 좋고, 수식처럼 표현할 수 있어 실무/교육 모두에서 널리 사용.


### 3. 언제 어떤 방식을 쓰는가?

| 상황/목적 | 추천 방식 | 이유/설명 |
| :-- | :-- | :-- |
| 2D 행렬 곱만 할 때 | `mm()` | 가장 빠르고 명확 |
| 다양한 차원 곱 필요할 때 | `matmul()` | 벡터, 행렬, 배치 모두 지원 |
| 가독성/수식형 코드 원할 때 | `@` | 파이썬 표준, 수식처럼 표현 가능, 내부적으로 matmul 사용 |
| 기존 메모리에 결과 저장 | `out=` 옵션 | 메모리 절약, inplace 연산은 지원하지 않음 |

### 4. 실무에서의 활용 ?

- **딥러닝 레이어 연산**: 대부분 `matmul` 또는 `@` 사용 (배치 곱이 많음)
- **행렬 곱만 반복**: `mm()`로 빠르고 단순하게 처리
- **코드 가독성/교육**: `@` 연산자 선호 (수식과 동일하게 보여서 직관적)
- **메모리 관리**: 대용량 연산에서 `out=` 옵션으로 불필요한 메모리 할당 방지


**정리:**

- **matmul**: 범용, 실무에서 가장 많이 사용
- **mm**: 2D 전용, 빠르고 단순
- **@**: 파이썬 표준, 가독성/수식형 코드에 최적
- **모두 새 메모리 생성**, 결과를 기존 텐서에 저장하려면 `out=` 사용